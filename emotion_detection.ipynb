{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zDT0sjnoVdW",
        "outputId": "70d037aa-98d5-482a-8282-646997ca8bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-17 06:42:27--  https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_1.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.96.128, 108.177.127.128, 172.217.218.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.96.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14174600 (14M) [application/octet-stream]\n",
            "Saving to: ‘data/full_dataset/goemotions_1.csv’\n",
            "\n",
            "goemotions_1.csv    100%[===================>]  13.52M  15.8MB/s    in 0.9s    \n",
            "\n",
            "2023-03-17 06:42:29 (15.8 MB/s) - ‘data/full_dataset/goemotions_1.csv’ saved [14174600/14174600]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -P data/full_dataset/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_1.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P data/full_dataset/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_2.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YblXQpWkpLi1",
        "outputId": "679a4a3c-6bd1-4927-f0a4-fa3dc225ea74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-17 06:42:29--  https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_2.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.96.128, 108.177.127.128, 172.217.218.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.96.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14173154 (14M) [application/octet-stream]\n",
            "Saving to: ‘data/full_dataset/goemotions_2.csv’\n",
            "\n",
            "goemotions_2.csv    100%[===================>]  13.52M  15.5MB/s    in 0.9s    \n",
            "\n",
            "2023-03-17 06:42:30 (15.5 MB/s) - ‘data/full_dataset/goemotions_2.csv’ saved [14173154/14173154]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P data/full_dataset/ https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_3.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp7HvRDfpSyX",
        "outputId": "cd4f3d7b-3aca-49fd-97d8-e6c7a77f786e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-17 06:42:30--  https://storage.googleapis.com/gresearch/goemotions/data/full_dataset/goemotions_3.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.96.128, 108.177.127.128, 172.217.218.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.96.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14395164 (14M) [application/octet-stream]\n",
            "Saving to: ‘data/full_dataset/goemotions_3.csv’\n",
            "\n",
            "goemotions_3.csv    100%[===================>]  13.73M  16.5MB/s    in 0.8s    \n",
            "\n",
            "2023-03-17 06:42:31 (16.5 MB/s) - ‘data/full_dataset/goemotions_3.csv’ saved [14395164/14395164]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "zoLghIYFpegr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_1 = './data/full_dataset/goemotions_1.csv'\n",
        "d1 = pd.read_csv(path_1)\n",
        "\n",
        "d1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ascHOSf5pVFY",
        "outputId": "15e1c750-ca98-4617-96a4-4f7c2b1b8816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_2 = './data/full_dataset/goemotions_2.csv'\n",
        "d2 = pd.read_csv(path_2)\n",
        "\n",
        "d2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97XRfzgvq-Za",
        "outputId": "2bb4819c-0e81-49db-f1c4-cd250ac9e72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_3 = './data/full_dataset/goemotions_3.csv'\n",
        "d3 = pd.read_csv(path_3)\n",
        "\n",
        "d3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDNZ-R1Hq_Jb",
        "outputId": "ffe30ce3-bc8b-427f-ae38-2ecf397586ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(71225, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"text\", \"id\", \"admiration\", \"annoyance\"]\n",
        "df = d1[['id','text','admiration','annoyance']]"
      ],
      "metadata": {
        "id": "XGOAdxNIqhFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g74QJGuepjZ9",
        "outputId": "8e509192-9787-4370-84d8-59751997d0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.concat([d1,d2,d3])"
      ],
      "metadata": {
        "id": "Gh955MmYq7av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all.shape, (len(d1) + len(d2) + len(d3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSTJ04XmrXYM",
        "outputId": "6ace928f-9e9a-4651-96e1-b1e80c82f896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((211225, 37), 211225)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_all.head(1).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FAwvDIS6xHwU",
        "outputId": "a82fc054-b9c0-44a2-f211-dd9d538a378e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    0\n",
              "text                  That game hurt.\n",
              "id                            eew5j0j\n",
              "author                          Brdd9\n",
              "subreddit                         nrl\n",
              "link_id                     t3_ajis4z\n",
              "parent_id                  t1_eew18eq\n",
              "created_utc              1548381039.0\n",
              "rater_id                            1\n",
              "example_very_unclear            False\n",
              "admiration                          0\n",
              "amusement                           0\n",
              "anger                               0\n",
              "annoyance                           0\n",
              "approval                            0\n",
              "caring                              0\n",
              "confusion                           0\n",
              "curiosity                           0\n",
              "desire                              0\n",
              "disappointment                      0\n",
              "disapproval                         0\n",
              "disgust                             0\n",
              "embarrassment                       0\n",
              "excitement                          0\n",
              "fear                                0\n",
              "gratitude                           0\n",
              "grief                               0\n",
              "joy                                 0\n",
              "love                                0\n",
              "nervousness                         0\n",
              "optimism                            0\n",
              "pride                               0\n",
              "realization                         0\n",
              "relief                              0\n",
              "remorse                             0\n",
              "sadness                             1\n",
              "surprise                            0\n",
              "neutral                             0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19ef80f1-bbbb-4470-8d11-a96766fb606d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>That game hurt.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>eew5j0j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>author</th>\n",
              "      <td>Brdd9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subreddit</th>\n",
              "      <td>nrl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>link_id</th>\n",
              "      <td>t3_ajis4z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parent_id</th>\n",
              "      <td>t1_eew18eq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>created_utc</th>\n",
              "      <td>1548381039.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rater_id</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>example_very_unclear</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>admiration</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amusement</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anger</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>annoyance</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>approval</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>caring</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>confusion</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>curiosity</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>desire</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disappointment</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disapproval</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disgust</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>embarrassment</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>excitement</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gratitude</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grief</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>joy</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>love</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nervousness</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>optimism</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pride</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>realization</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>relief</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>remorse</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sadness</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprise</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19ef80f1-bbbb-4470-8d11-a96766fb606d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19ef80f1-bbbb-4470-8d11-a96766fb606d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19ef80f1-bbbb-4470-8d11-a96766fb606d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"text\", \"id\", \"admiration\", \"annoyance\"]\n",
        "df = df_all[['id','text','admiration','annoyance']]"
      ],
      "metadata": {
        "id": "km5Doy-orbkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.admiration.value_counts(normalize = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yUIMZUTrjps",
        "outputId": "e88419e9-9acc-45f9-ffba-f87ab3946705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.918897\n",
              "1    0.081103\n",
              "Name: admiration, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(df.admiration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzxpe8sbxQvx",
        "outputId": "d6e41fde-38b9-46bd-f269-1ffda21e5e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 194094, 1: 17131})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(df.annoyance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_Ks4a2qro5a",
        "outputId": "8c9ac205-5b68-4b58-f496-0ade545dfbec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 197607, 1: 13618})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.annoyance.value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k5MWcU2yCE-",
        "outputId": "ccbceafb-7f12-43c3-cc50-b46cc20668b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.935528\n",
              "1    0.064472\n",
              "Name: annoyance, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_admiration = df_all[df_all.admiration == 1]\n",
        "df_annoyance = df_all[df_all.annoyance == 1]"
      ],
      "metadata": {
        "id": "-9Pbg74arpJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_admiration = df_admiration.text.tolist()\n",
        "data_annoyance = df_annoyance.text.tolist()"
      ],
      "metadata": {
        "id": "lBjkkLW3r25P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TumVn6ZxsgGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adm_len = len(data_admiration)\n",
        "ann_len = len(data_annoyance)\n",
        "\n",
        "adm_len/(adm_len + ann_len), ann_len/(adm_len + ann_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS9eMsxxyX1h",
        "outputId": "e5b6fe13-2413-474d-d1c5-174a98fe5bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5571238089043546, 0.4428761910956454)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_annoyance[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ovzT7Xshzu",
        "outputId": "162a9852-4e20-4ca6-b373-8f86d20898b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"For extra measure tape it right by your crotch so she can't take it for sexual assault reasons\",\n",
              " 'Go troll elsewhere. This woman needs support, not crass questions.',\n",
              " \"Just rumors online, it most likely won't happen\",\n",
              " 'Good old guardian refusing to accept that [NAME] is stauncly anti-EU and anti-Brussels',\n",
              " \"Do you not give your snowmen brooms? I feel like that's a thing people do\",\n",
              " 'Calm down.',\n",
              " 'I mean that’s a stupid rule that creates an echo chamber, but I don’t see how that belongs here.',\n",
              " \"[NAME] has always favoured [NAME] so I'd assume this means he's the next up, I just prefer [NAME] and find [NAME] a little overrated.\",\n",
              " 'Yes, at home recuperating from a fractured ankle. ',\n",
              " 'So wrong. Most every denomination believes they are the only ones who are doing it right and everyone else is going to rot in hell.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 20\n",
        "data_annoyance[idx:idx+10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tggy48IXyyE_",
        "outputId": "b66355c9-1524-4fb4-f92d-771122c6ce97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What a douche canoe to take advantage of you like that.',\n",
              " 'Man I hate kids',\n",
              " \"[NAME] damn it I'm so tired of seeing Instagram between fights\",\n",
              " 'Who still unironically says SJWs? You look like an idiot saying that.',\n",
              " 'I have a deep seeded hatred for close-minded people too.',\n",
              " 'Look [NAME] is here \"Where the fuck was he an hour ago, gary, where!?\"',\n",
              " 'State of [NAME] trying to be funny and spelling ‘lose’ wrong',\n",
              " 'That sucks! Your lady giblets are NONE of her damn business. Does your BF at least try to curb her mouth?',\n",
              " 'dude people here can be assholes. there’s nothing wrong with taking a break.',\n",
              " \"He told you that he hates your friends because they don't beat you up? That is so disgusting!\"]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_admiration[:10]"
      ],
      "metadata": {
        "id": "eqkekU0Dsl_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f3b9f4-9657-43eb-a2ba-833eb723c912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I appreciate it, that's good to know. I hope I'll have to apply that knowledge one day\",\n",
              " \"Pretty much every Punjabi dude I've met.\",\n",
              " 'Lots, play store or apple store vpn. Nord is good',\n",
              " \"nice!! I'll try this one\",\n",
              " 'She’s like a kewpie doll with them. Precious.',\n",
              " \"Nice. I'll look around for it. Thanks!\",\n",
              " 'I loved how [NAME] feels like everyone in the office is her family. Her relationship with [NAME] is so cute and innocent',\n",
              " 'I thought it was very good. The guy was one sick bastard that’s for sure.',\n",
              " 'Best side quest ever!',\n",
              " 'I love that smile of his!!!!']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "labeled_texts = []\n",
        "for text in data_admiration:\n",
        "    labeled_texts.append((text, 1))\n",
        "for text in data_annoyance:\n",
        "    labeled_texts.append((text, 0))\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    [text[0] for text in labeled_texts], \n",
        "    [text[1] for text in labeled_texts], \n",
        "    test_size=0.1,                       \n",
        "    random_state=42,                     \n",
        "    stratify=[text[1] for text in labeled_texts] \n",
        ")\n"
      ],
      "metadata": {
        "id": "F_ffZqJdyreY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_texts), len(test_texts), Counter(train_labels), Counter(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLMgfouf1ott",
        "outputId": "77b1c6f6-4d52-4a79-d439-4ae7ca351f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27674, 3075, Counter({1: 15418, 0: 12256}), Counter({1: 1713, 0: 1362}))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRWhqL6w1z0K",
        "outputId": "a48ac7ae-5528-41a2-a0d4-caee155d7bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "UweV4TvC2Vyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_texts), Counter(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMXloU-_2o4n",
        "outputId": "16928f67-ee5c-43b6-ed02-683f6235f510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27674, Counter({1: 15418, 0: 12256}))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts,\n",
        "                                                                    train_labels,\n",
        "                                                                    test_size=0.1, \n",
        "                                                                    random_state = 42)"
      ],
      "metadata": {
        "id": "4Knr_ul32Wxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_texts) + len(val_texts), Counter(train_labels), Counter(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANXCSX_O2tDG",
        "outputId": "3b976448-4ab1-4f65-8064-9d8162d22a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27674, Counter({1: 13896, 0: 11010}), Counter({0: 1246, 1: 1522}))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_texts, train_labels\n",
        "#val_texts, val_labels\n",
        "#test_texts, test_labels"
      ],
      "metadata": {
        "id": "gmxutrNp2wr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.max_len_single_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IenuDqXn7wGr",
        "outputId": "3e9b9689-5851-429d-df5b-6735e4c0c90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "510"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "Sn23HqrH6ewF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_texts), len(train_encodings), "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEY8PyCF6gog",
        "outputId": "f15bb76a-6590-4a10-df48-8aff3270dc6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24906, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_encodings[24905].encoding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "l096El986z5z",
        "outputId": "7a25a7ed-5a13-42e7-cd8a-5ec1e5351860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-93cc4640daba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m24905\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tokenizers.Encoding' object has no attribute 'encoding'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_encodings[0].tokens[:30], train_encodings[0].attention_mask[:30], train_encodings[0].special_tokens_mask[:30]"
      ],
      "metadata": {
        "id": "yKnsCZZL7FWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = dataset(train_encodings, train_labels)\n",
        "val_dataset = dataset(val_encodings, val_labels)\n",
        "test_dataset = dataset(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "G8WgVv396B-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset.labels), len(train_dataset.encodings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnUvzFkI7E3E",
        "outputId": "506d4387-4ab9-4aec-ef87-5f115e51766a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24906, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DistilBertForSequenceClassification, AdamW\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "optim = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-PNs060SGw1",
        "outputId": "292a2550-f9a0-4bd4-acbb-88037ea84f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwErhm_HUf4W",
        "outputId": "d3edca21-4178-4f4a-de59-3d709a68dbef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24906"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):\n",
        "  print(f\"epoch - {epoch}\")\n",
        "  bt = 0\n",
        "  for batch in train_loader:\n",
        "      optim.zero_grad()\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "      outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "      loss = outputs[0]\n",
        "      if bt % 500 == 0:\n",
        "        print(f\"epoch - {epoch} batch - {bt} - loss - {loss.item()}\")\n",
        "      bt += 1\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "  print(f\"end of epoch {epoch} - total batches - {bt}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkLIfjnI8aPI",
        "outputId": "ebf9b581-df56-4061-c164-f4fdfcdb5c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 0\n",
            "epoch - 0 batch - 0 - loss - 0.6789759397506714\n",
            "epoch - 0 batch - 500 - loss - 0.10679575800895691\n",
            "epoch - 0 batch - 1000 - loss - 0.09133709967136383\n",
            "epoch - 0 batch - 1500 - loss - 0.5891621708869934\n",
            "end of epoch 0 - total batches - 1557\n",
            "epoch - 1\n",
            "epoch - 1 batch - 0 - loss - 0.05004775524139404\n",
            "epoch - 1 batch - 500 - loss - 0.19975194334983826\n",
            "epoch - 1 batch - 1000 - loss - 0.4474211633205414\n",
            "epoch - 1 batch - 1500 - loss - 0.3487479090690613\n",
            "end of epoch 1 - total batches - 1557\n",
            "epoch - 2\n",
            "epoch - 2 batch - 0 - loss - 0.10343366116285324\n",
            "epoch - 2 batch - 500 - loss - 0.05225159972906113\n",
            "epoch - 2 batch - 1000 - loss - 0.14451129734516144\n",
            "epoch - 2 batch - 1500 - loss - 0.047133270651102066\n",
            "end of epoch 2 - total batches - 1557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.eval()"
      ],
      "metadata": {
        "id": "DmA4DcYNSM6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "TQaoKthBYwyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.eval()"
      ],
      "metadata": {
        "id": "BE1fX7vnZNPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "val_texts[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHKhKylIjU-v",
        "outputId": "15b112ee-19de-488a-b8ae-1b5ac47aa0a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The general rule is that [NAME] is talking rubbish whenever he opens his mouth.',\n",
              " 'I for one think that the military of no country should be this strong either.',\n",
              " 'Your Mom was ruled by [NAME] dynasty that happened to be Macedonian for the next three centuries.']"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txts = val_texts[:10]\n",
        "\n",
        "txts_enc = tokenizer(txts, truncation=True, padding=True)\n",
        "txts_dataset = dataset(txts_enc, None)\n"
      ],
      "metadata": {
        "id": "7AkdhP26bywI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txts = [\n",
        "    \"Actually, it's pronounced...\",\n",
        "    \"Well, *actually*...\",\n",
        "    \"I'm sorry, but I can't help but correct you...\",\n",
        "    \"I can't believe you don't know that...\",\n",
        "    \"Um, excuse me, but...\",\n",
        "    \"That's not how it works, let me explain...\",\n",
        "    \"You're wrong, let me tell you why...\",\n",
        "    \"I hate to be that person, but...\",\n",
        "    \"Can I just say something?\",\n",
        "    \"I'm not trying to be rude, but...\",\n",
        "    \"You should already know this...\",\n",
        "    \"I'm surprised you haven't heard of this before...\",\n",
        "    \"I'm just trying to help you improve...\",\n",
        "    \"I think you're mistaken...\",\n",
        "    \"I'm sorry, but that's just not true...\",\n",
        "    \"Do you even know what you're talking about?\",\n",
        "    \"You're missing the point...\",\n",
        "    \"It's not that difficult to understand...\",\n",
        "    \"I don't think you get it...\",\n",
        "    \"You need to educate yourself on this topic...\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "-A0NDNEijbD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txts = [\n",
        "    \"I admire your dedication to your craft.\",\n",
        "    \"You have an incredible work ethic that I look up to.\",\n",
        "    \"I am in awe of your ability to think creatively and solve problems.\",\n",
        "    \"You inspire me with your passion for making the world a better place.\",\n",
        "    \"Your perseverance in the face of adversity is truly inspiring.\",\n",
        "    \"I am impressed by your ability to stay calm and focused under pressure.\",\n",
        "    \"Your kindness and empathy towards others is something I aspire to.\",\n",
        "    \"I have the utmost respect for your honesty and integrity.\",\n",
        "    \"You have a unique perspective that I find fascinating and enlightening.\",\n",
        "    \"Your generosity and willingness to help others is truly admirable.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "e_eGwUEJkSdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_texts = tokenizer(txts, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "outputs = model(encoded_texts['input_ids'], attention_mask=encoded_texts['attention_mask'])\n",
        "outs = F.softmax(outputs.logits, dim = 1)\n",
        "predicted_labels = torch.argmax(outs, dim=1)\n",
        "predicted_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za7l819HeVfg",
        "outputId": "f9f6a53f-01ef-4bd4-c449-509595470aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tatn9-3Se6d2",
        "outputId": "f2075ed0-3013-40f6-9df3-5efdff6f4e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6.4267e-04, 9.9936e-01],\n",
              "        [6.9036e-04, 9.9931e-01],\n",
              "        [1.3843e-01, 8.6157e-01],\n",
              "        [8.1132e-04, 9.9919e-01],\n",
              "        [2.2913e-02, 9.7709e-01],\n",
              "        [2.4930e-03, 9.9751e-01],\n",
              "        [2.6843e-02, 9.7316e-01],\n",
              "        [7.0157e-04, 9.9930e-01],\n",
              "        [6.8766e-04, 9.9931e-01],\n",
              "        [2.8995e-03, 9.9710e-01]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_th3C-5euIf",
        "outputId": "24d5a611-28c6-4bd0-f363-7cc42f28964f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-128-5b3713794976>:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  F.softmax(outputs.logits)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7.1340e-04, 9.9929e-01]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txts_dataset.encodings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qww1aQjcxuP",
        "outputId": "7bb9a1f5-4f91-4e0a-de0a-cff6e4f72072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 2008, 2015, 2428, 2307, 3105, 2567, 1010, 1045, 19837, 2115, 7729, 102, 0, 0, 0], [101, 1045, 2064, 1005, 1056, 8622, 2032, 1010, 2064, 2002, 2074, 6616, 2125, 2085, 999, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model(txts_dataset.encodings.input_ids, attention_mask=txts_dataset.encodings.attention_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "yig7kAytcYjp",
        "outputId": "983c097e-b777-43fa-dc5f-668178a3010c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-3b27cf357b28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxts_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtxts_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txts_enc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWlo4ZSPcUj6",
        "outputId": "47b37b6b-73ec-4968-d370-4fbe5cbb511c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 2008, 2015, 2428, 2307, 3105, 2567, 1010, 1045, 19837, 2115, 7729, 102, 0, 0, 0], [101, 1045, 2064, 1005, 1056, 8622, 2032, 1010, 2064, 2002, 2074, 6616, 2125, 2085, 999, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4F_RE0ydsMW",
        "outputId": "3312cbe1-b76c-4d2d-9dae-84f511f7a2ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ips = torch.Tensor(txts_enc.input_ids)\n",
        "am = torch.Tensor(txts_enc.attention_mask)\n",
        "ips = ips.to(device)\n",
        "am = am.to(device)"
      ],
      "metadata": {
        "id": "Bc9PfKnScTPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model(ips, attention_mask = am)"
      ],
      "metadata": {
        "id": "ruYCNIjVdaDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "  tb = batch\n",
        "  input_ids = batch['input_ids'].to(device)\n",
        "  attention_mask = batch['attention_mask'].to(device)\n",
        "  labels = batch['labels'].to(device)\n",
        "  outputs = model(input_ids, attention_mask=attention_mask)\n",
        "  break"
      ],
      "metadata": {
        "id": "e3Fkd_WUZog3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-mpkffPaMV1",
        "outputId": "09d6a3aa-7721-4c86-ea31-26f4bf05d115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(outputs.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtQFpUmNb4kP",
        "outputId": "cc30e43f-bc38-4dfe-a90f-0d6d037ddd03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-101-5b3713794976>:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  F.softmax(outputs.logits)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.8584e-01, 1.4157e-02],\n",
              "        [2.1578e-03, 9.9784e-01],\n",
              "        [3.3390e-03, 9.9666e-01],\n",
              "        [9.9215e-01, 7.8513e-03],\n",
              "        [1.8199e-01, 8.1801e-01],\n",
              "        [9.9239e-01, 7.6119e-03],\n",
              "        [9.7958e-01, 2.0423e-02],\n",
              "        [9.9270e-01, 7.3036e-03],\n",
              "        [7.8171e-01, 2.1829e-01],\n",
              "        [5.1501e-03, 9.9485e-01],\n",
              "        [1.8676e-01, 8.1324e-01],\n",
              "        [9.9051e-01, 9.4920e-03],\n",
              "        [8.6019e-01, 1.3981e-01],\n",
              "        [1.0404e-03, 9.9896e-01],\n",
              "        [4.0835e-01, 5.9165e-01],\n",
              "        [8.9042e-04, 9.9911e-01]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "qh22R4zoa59e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(outputs.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVqXZYG5Z40t",
        "outputId": "902ece8c-de2e-45fc-b49b-3bc285640fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-98-5b3713794976>:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  F.softmax(outputs.logits)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.9176e-01, 8.2382e-03],\n",
              "        [9.9236e-01, 7.6358e-03],\n",
              "        [2.5345e-03, 9.9747e-01],\n",
              "        [7.6250e-01, 2.3750e-01],\n",
              "        [7.6553e-04, 9.9923e-01],\n",
              "        [9.9090e-01, 9.1043e-03],\n",
              "        [9.9415e-01, 5.8475e-03],\n",
              "        [9.8687e-01, 1.3133e-02],\n",
              "        [8.9414e-04, 9.9911e-01],\n",
              "        [1.0758e-03, 9.9892e-01],\n",
              "        [9.6688e-01, 3.3124e-02],\n",
              "        [2.3114e-02, 9.7689e-01],\n",
              "        [9.9457e-01, 5.4306e-03],\n",
              "        [8.4372e-01, 1.5628e-01],\n",
              "        [9.8910e-01, 1.0901e-02],\n",
              "        [2.3501e-02, 9.7650e-01]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in val_loader:\n",
        "  outs = model(batch)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "nnbSlxPwZH26",
        "outputId": "e0072bfe-0fe2-41e1-97cf-bb26e5d99268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-c3e92f662301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "16 * 1557"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-6q6o6HZCr5",
        "outputId": "4fcfcc06-151a-4824-d421-013245ac9145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24912"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_directory = './'\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)"
      ],
      "metadata": {
        "id": "zZJp8b2TbR1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = dataset(val_encodings, val_labels)\n",
        "test_dataset = dataset(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "LAnso68FY93T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}